<!DOCTYPE html>
<html lang="de">
<head>
<meta charset="utf-8">
<title>STT Demo</title>
<style>
  * { box-sizing: border-box; margin: 0; padding: 0; }
  body { font-family: system-ui, sans-serif; background: #1a1a2e; color: #e0e0e0; display: flex; justify-content: center; padding: 2rem; }
  .card { background: #16213e; border-radius: 12px; padding: 2rem; max-width: 560px; width: 100%; box-shadow: 0 4px 24px rgba(0,0,0,.4); }
  h1 { font-size: 1.4rem; margin-bottom: 1.2rem; color: #a8d8ea; }
  label { display: block; font-size: .85rem; color: #8899aa; margin-bottom: .3rem; }
  input[type=text] {
    width: 100%; padding: .5rem .8rem; border: 1px solid #2a3a5c; border-radius: 6px;
    background: #0f3460; color: #e0e0e0; font-size: .9rem; margin-bottom: 1rem;
  }
  button {
    width: 100%; padding: .8rem; border: none; border-radius: 6px;
    font-size: 1rem; font-weight: 600; cursor: pointer; transition: background .2s;
  }
  #btn-rec { background: #e94560; color: #fff; }
  #btn-rec:hover { background: #c73e54; }
  #btn-rec.recording { background: #28a745; }
  #btn-rec.recording:hover { background: #218838; }
  #level-bar { margin-top: 1rem; height: 6px; border-radius: 3px; background: #0f3460; overflow: hidden; }
  #level-fill { height: 100%; width: 0%; background: #e94560; transition: width 60ms; }
  #transcript {
    margin-top: 1.2rem; min-height: 160px; max-height: 400px; overflow-y: auto;
    background: #0f3460; border-radius: 6px; padding: 1rem; font-size: .95rem;
    line-height: 1.5; white-space: pre-wrap; word-break: break-word;
  }
  #transcript:empty::before { content: 'Transkription erscheint hier...'; color: #556; }
  #status { margin-top: .8rem; font-size: .85rem; color: #8899aa; min-height: 1.2em; }
  .seg { color: #e0e0e0; }
  .seg .time { color: #5588aa; font-size: .8rem; margin-right: .4rem; }
</style>
</head>
<body>
<div class="card">
  <h1>Speech-to-Text (Mikrofon)</h1>

  <label for="api-url">Server-URL</label>
  <input type="text" id="api-url" value="https://srv.launix.de/tts">

  <button id="btn-rec">Aufnahme starten</button>
  <div id="level-bar"><div id="level-fill"></div></div>
  <div id="transcript"></div>
  <div id="status"></div>
</div>

<script>
const apiInput   = document.getElementById('api-url');
const btn        = document.getElementById('btn-rec');
const transcript = document.getElementById('transcript');
const statusEl   = document.getElementById('status');
const levelFill  = document.getElementById('level-fill');

const params = new URLSearchParams(location.search);
if (params.get('api')) apiInput.value = params.get('api');

let recording = false;
let mediaStream = null;
let audioCtx = null;
let analyser = null;
let scriptNode = null;
let levelRaf = null;
let ws = null;

function fmtTime(s) {
  const m = Math.floor(s / 60);
  const sec = (s % 60).toFixed(1);
  return m > 0 ? m + ':' + sec.padStart(4, '0') : sec + 's';
}

function addSegment(seg) {
  const div = document.createElement('div');
  div.className = 'seg';
  const timeSpan = document.createElement('span');
  timeSpan.className = 'time';
  timeSpan.textContent = '[' + fmtTime(seg.start) + '-' + fmtTime(seg.end) + ']';
  div.appendChild(timeSpan);
  div.appendChild(document.createTextNode(seg.text));
  transcript.appendChild(div);
  transcript.scrollTop = transcript.scrollHeight;
}

function updateLevel() {
  if (!analyser) return;
  const buf = new Uint8Array(analyser.fftSize);
  analyser.getByteTimeDomainData(buf);
  let sum = 0;
  for (let i = 0; i < buf.length; i++) {
    const v = (buf[i] - 128) / 128;
    sum += v * v;
  }
  const rms = Math.sqrt(sum / buf.length);
  levelFill.style.width = Math.min(100, rms * 400) + '%';
  if (recording) levelRaf = requestAnimationFrame(updateLevel);
}

async function start() {
  transcript.innerHTML = '';
  statusEl.textContent = 'Mikrofon wird angefordert...';

  try {
    mediaStream = await navigator.mediaDevices.getUserMedia({
      audio: { channelCount: 1, echoCancellation: false, noiseSuppression: false }
    });
  } catch (e) {
    statusEl.textContent = 'Mikrofon-Zugriff verweigert: ' + e.message;
    return;
  }

  audioCtx = new AudioContext();
  const nativeRate = audioCtx.sampleRate;
  const source = audioCtx.createMediaStreamSource(mediaStream);

  analyser = audioCtx.createAnalyser();
  analyser.fftSize = 512;
  source.connect(analyser);

  // Build WebSocket URL from the HTTP API URL
  const api = apiInput.value.replace(/\/+$/, '');
  const wsUrl = api.replace(/^http/, 'ws') + '/ws/stt';

  statusEl.textContent = 'Verbinde mit ' + wsUrl + '...';

  ws = new WebSocket(wsUrl);
  ws.binaryType = 'arraybuffer';

  ws.onopen = function() {
    // Send initial config with sample rate
    ws.send(JSON.stringify({ sampleRate: nativeRate, language: 'de' }));

    // Start capturing PCM audio
    const bufSize = 4096;
    scriptNode = audioCtx.createScriptProcessor(bufSize, 1, 1);
    scriptNode.onaudioprocess = function(e) {
      if (!recording || !ws || ws.readyState !== WebSocket.OPEN) return;
      const float32 = e.inputBuffer.getChannelData(0);
      const int16 = new Int16Array(float32.length);
      for (let i = 0; i < float32.length; i++) {
        int16[i] = Math.max(-32768, Math.min(32767, Math.round(float32[i] * 32767)));
      }
      ws.send(int16.buffer);
    };
    source.connect(scriptNode);
    scriptNode.connect(audioCtx.destination);

    recording = true;
    btn.textContent = 'Aufnahme stoppen';
    btn.classList.add('recording');
    statusEl.textContent = 'Streaming... (' + nativeRate + ' Hz)';
    updateLevel();
  };

  ws.onmessage = function(evt) {
    if (typeof evt.data === 'string') {
      if (evt.data === '__END__') {
        statusEl.textContent = 'Fertig.';
        return;
      }
      try {
        addSegment(JSON.parse(evt.data));
      } catch (_) {}
    }
  };

  ws.onerror = function() {
    statusEl.textContent = 'WebSocket-Fehler';
  };

  ws.onclose = function() {
    if (recording) stop();
    statusEl.textContent = 'Verbindung geschlossen.';
  };
}

async function stop() {
  recording = false;
  btn.textContent = 'Aufnahme starten';
  btn.classList.remove('recording');
  levelFill.style.width = '0%';
  if (levelRaf) cancelAnimationFrame(levelRaf);
  if (scriptNode) { scriptNode.disconnect(); scriptNode = null; }
  if (analyser) { analyser.disconnect(); analyser = null; }
  if (mediaStream) { mediaStream.getTracks().forEach(t => t.stop()); mediaStream = null; }
  if (audioCtx) { audioCtx.close(); audioCtx = null; }

  // Send END sentinel and close WebSocket
  if (ws && ws.readyState === WebSocket.OPEN) {
    ws.send('__END__');
    statusEl.textContent = 'Warte auf letzte Ergebnisse...';
    // Don't close immediately â€” wait for server's __END__ response
  }
}

btn.addEventListener('click', () => {
  if (recording) stop(); else start();
});
</script>
</body>
</html>
