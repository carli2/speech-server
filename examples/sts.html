<!DOCTYPE html>
<html lang="de">
<head>
<meta charset="utf-8">
<title>Speech-to-Speech Demo</title>
<style>
  * { box-sizing: border-box; margin: 0; padding: 0; }
  body { font-family: system-ui, sans-serif; background: #1a1a2e; color: #e0e0e0; display: flex; justify-content: center; padding: 2rem; }
  .card { background: #16213e; border-radius: 12px; padding: 2rem; max-width: 560px; width: 100%; box-shadow: 0 4px 24px rgba(0,0,0,.4); }
  h1 { font-size: 1.4rem; margin-bottom: 1.2rem; color: #a8d8ea; }
  label { display: block; font-size: .85rem; color: #8899aa; margin-bottom: .3rem; }
  input[type=text], select {
    width: 100%; padding: .5rem .8rem; border: 1px solid #2a3a5c; border-radius: 6px;
    background: #0f3460; color: #e0e0e0; font-size: .9rem; margin-bottom: 1rem;
  }
  .row { display: flex; gap: .8rem; margin-bottom: 1rem; }
  .row > * { flex: 1; }
  button {
    width: 100%; padding: .8rem; border: none; border-radius: 6px;
    font-size: 1rem; font-weight: 600; cursor: pointer; transition: background .2s;
  }
  #btn-rec { background: #e94560; color: #fff; }
  #btn-rec:hover { background: #c73e54; }
  #btn-rec.recording { background: #28a745; }
  #btn-rec.recording:hover { background: #218838; }
  #level-bar { margin-top: 1rem; height: 6px; border-radius: 3px; background: #0f3460; overflow: hidden; }
  #level-fill { height: 100%; width: 0%; background: #e94560; transition: width 60ms; }
  #transcript {
    margin-top: 1.2rem; min-height: 120px; max-height: 300px; overflow-y: auto;
    background: #0f3460; border-radius: 6px; padding: 1rem; font-size: .95rem;
    line-height: 1.5; white-space: pre-wrap; word-break: break-word;
  }
  #transcript:empty::before { content: 'Sprich etwas — Text und Roboterstimme kommen hier...'; color: #556; }
  #status { margin-top: .8rem; font-size: .85rem; color: #8899aa; min-height: 1.2em; }
  .seg { color: #e0e0e0; }
  .seg .time { color: #5588aa; font-size: .8rem; margin-right: .4rem; }
  .seg .speaking { color: #28a745; font-size: .8rem; margin-left: .4rem; }
</style>
</head>
<body>
<div class="card">
  <h1>Speech-to-Speech (Roboterstimme)</h1>

  <label for="api-url">Server-URL</label>
  <input type="text" id="api-url" value="https://srv.launix.de/tts">

  <div class="row">
    <div>
      <label for="voice">Stimme</label>
      <input type="text" id="voice" value="de_DE-thorsten-medium">
    </div>
    <div>
      <label for="profile">Codec-Profil</label>
      <select id="profile">
        <option value="low">low</option>
        <option value="medium" selected>medium</option>
        <option value="high">high</option>
        <option value="full">full</option>
      </select>
    </div>
  </div>

  <button id="btn-rec">Aufnahme starten</button>
  <div id="level-bar"><div id="level-fill"></div></div>
  <div id="transcript"></div>
  <div id="status"></div>
</div>

<script src="codec.js"></script>
<script>
var Codec = AudioCodec;
var apiInput   = document.getElementById('api-url');
var voiceInput = document.getElementById('voice');
var profileSel = document.getElementById('profile');
var btn        = document.getElementById('btn-rec');
var transcript = document.getElementById('transcript');
var statusEl   = document.getElementById('status');
var levelFill  = document.getElementById('level-fill');

var params = new URLSearchParams(location.search);
if (params.get('api')) apiInput.value = params.get('api');
if (params.get('voice')) voiceInput.value = params.get('voice');
if (params.get('profile')) profileSel.value = params.get('profile');

var recording = false;
var pipeWs = null;
var codecWs = null;
var mic = null;
var speaker = null;
var sessionId = null;

function uuid() {
  return 'xxxx-xxxx'.replace(/x/g, function () { return (Math.random() * 16 | 0).toString(16); });
}

function fmtTime(s) {
  var m = Math.floor(s / 60);
  var sec = (s % 60).toFixed(1);
  return m > 0 ? m + ':' + sec.padStart(4, '0') : sec + 's';
}

function addSegment(seg, extra) {
  var div = document.createElement('div');
  div.className = 'seg';
  var timeSpan = document.createElement('span');
  timeSpan.className = 'time';
  timeSpan.textContent = '[' + fmtTime(seg.start) + '-' + fmtTime(seg.end) + ']';
  div.appendChild(timeSpan);
  div.appendChild(document.createTextNode(seg.text));
  if (extra) {
    var sp = document.createElement('span');
    sp.className = 'speaking';
    sp.textContent = extra;
    div.appendChild(sp);
  }
  transcript.appendChild(div);
  transcript.scrollTop = transcript.scrollHeight;
}

async function start() {
  transcript.innerHTML = '';
  statusEl.textContent = 'Verbinde...';
  sessionId = uuid();
  var profile = profileSel.value;
  var voice = voiceInput.value.trim() || 'de_DE-thorsten-medium';
  var api = apiInput.value.replace(/\/+$/, '');
  var wsBase = api.replace(/^http/, 'ws');

  // Duplex pipeline:
  //   RX: codec → resample → STT → NDJSON text out on this WS
  //   TX: text in on this WS → TTS → resample → codec
  var pipeConfig = {
    pipes: [
      'codec:' + sessionId + ' | resample:48000:16000 | stt:de | ws:ndjson',
      'ws:text | tts:' + voice + ' | resample:22050:48000 | codec:' + sessionId
    ]
  };

  pipeWs = new WebSocket(wsBase + '/ws/pipe');
  pipeWs.binaryType = 'arraybuffer';

  pipeWs.onopen = function () {
    pipeWs.send(JSON.stringify(pipeConfig));
    statusEl.textContent = 'Pipeline gestartet, verbinde Codec...';
    connectCodec();
  };

  pipeWs.onmessage = function (evt) {
    if (typeof evt.data === 'string') {
      if (evt.data === '__END__') {
        statusEl.textContent = 'Fertig.';
        return;
      }
      try {
        var seg = JSON.parse(evt.data);
        addSegment(seg, '▶');
        // Forward recognized text back to pipe WS for TTS
        if (pipeWs && pipeWs.readyState === WebSocket.OPEN && seg.text) {
          pipeWs.send(seg.text);
        }
      } catch (_) {}
    }
  };

  pipeWs.onerror = function () { statusEl.textContent = 'Pipeline WebSocket-Fehler'; };
  pipeWs.onclose = function () {
    if (recording) stop();
    statusEl.textContent = 'Verbindung geschlossen.';
  };
}

function connectCodec() {
  var api = apiInput.value.replace(/\/+$/, '');
  var wsBase = api.replace(/^http/, 'ws');
  var profile = profileSel.value;

  codecWs = new WebSocket(wsBase + '/ws/socket/' + sessionId);
  codecWs.binaryType = 'arraybuffer';

  codecWs.onopen = function () {
    codecWs.send(JSON.stringify({ type: 'hello', profiles: [profile] }));
  };

  codecWs.onmessage = function (evt) {
    if (typeof evt.data !== 'string') return;
    try {
      var obj = JSON.parse(evt.data);
      if (obj.type === 'hello') {
        statusEl.textContent = 'Streaming... (Profil: ' + obj.profile + ', STT → TTS)';
        openChannels();
      }
      if (obj.error) statusEl.textContent = 'Fehler: ' + obj.error;
    } catch (_) {}
  };

  codecWs.onerror = function () { statusEl.textContent = 'Codec WebSocket-Fehler'; };
  codecWs.onclose = function () {
    if (recording) stop();
  };
}

function openChannels() {
  // Speaker: receive TTS audio from codec socket
  speaker = Codec.openSpeaker(codecWs);

  // Mic: send audio to codec socket
  Codec.openMic(codecWs, profileSel.value).then(function (h) {
    mic = h;
    recording = true;
    btn.textContent = 'Aufnahme stoppen';
    btn.classList.add('recording');
    mic.onrms = function (rms) {
      levelFill.style.width = Math.min(100, rms * 400) + '%';
    };
  }).catch(function (e) {
    statusEl.textContent = 'Mikrofon-Zugriff verweigert: ' + e.message;
  });
}

function stop() {
  recording = false;
  btn.textContent = 'Aufnahme starten';
  btn.classList.remove('recording');
  levelFill.style.width = '0%';

  if (mic) { mic.close(); mic = null; }
  if (speaker) { speaker.close(); speaker = null; }
  if (codecWs && codecWs.readyState === WebSocket.OPEN) {
    codecWs.send('__END__');
    codecWs.close();
  }
  codecWs = null;
  if (pipeWs && pipeWs.readyState === WebSocket.OPEN) {
    pipeWs.send('__END__');
  }
  statusEl.textContent = 'Warte auf letzte Ergebnisse...';
}

btn.addEventListener('click', function () {
  if (recording) stop(); else start();
});
</script>
</body>
</html>
